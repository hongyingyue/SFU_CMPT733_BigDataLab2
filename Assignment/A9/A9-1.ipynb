{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9: Hypothesis Testing (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many situations, we cannot get the full population but only a sample. If we derive an interesting result from a sample, how likely can we derive the same result from the entire population? In other words, we want to know whether this result is a true finding or it just happens in the sample by chance. Hypothesis testing aims to answer this fundamental question. \n",
    "\n",
    "\n",
    "**Hypothesis Testing**\n",
    "1. Why A/B testing?  \n",
    "2. What is a permutation test? How to implement it?\n",
    "3. What is p-value? How to avoid p-hacking? \n",
    "4. What is a chi-squared test? How to implement it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. A/B Testing\n",
    "> Acknowledgment: Thank [Greg Baker](http://www.cs.sfu.ca/~ggbaker/) for helping me to prepare this task.\n",
    "\n",
    "A very common technique to evaluate changes in a user interface is A/B testing: show some users interface A, some interface B, and then look to see if one performs better than the other.\n",
    "\n",
    "Suppose I started an A/B test on CourSys. Here are the two interfaces that I want to compare with. I want to know whether a good placeholder in the search box can attract more users to use the `search` feature.\n",
    "\n",
    "\n",
    "![](img/ab-testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided [searchlog.json](searchlog.json) has information about users' usage. The question I was interested in: is the number of searches per user different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we need to first pick up a **test statistic** to quantify how good an interface is. Here, we choose \"the search_count mean\". \n",
    "\n",
    "Please write the code to compute **the difference of the search_count means between interface A and Interface B.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13500569535052287"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json('searchlog.json', lines=True)\n",
    "group_a = df[df['search_ui']=='A'].search_count\n",
    "group_b = df[df['search_ui']=='B'].search_count\n",
    "\n",
    "diff = group_b.mean() - group_a.mean() \n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we find that the mean value increased by 0.135. Then, we wonder whether this result is just caused by random variation. \n",
    "\n",
    "We define the Null Hypothesis as\n",
    " * The difference in search_count mean between Interface A and Interface B is caused by random variation. \n",
    " \n",
    "Then the next job is to check whether we can reject the null hypothesis or not. If it does, we can adopt the alternative explanation:\n",
    " * The difference in search_count mean  between Interface A and Interface B is caused by the design differences between the two.\n",
    "\n",
    "We compute the p-value of the observed result. If p-value is low (e.g., <0.01), we can reject the null hypothesis, and adopt  the alternative explanation.  \n",
    "\n",
    "Please implement a permutation test (numSamples = 10000) to compute the p-value. Note that you are NOT allowed to use an implementation in an existing library. You have to implement it by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.1352\n"
     ]
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "def permutation_test(group1, group2, num_samples=10000):\n",
    "    observed_diff = np.mean(group2) - np.mean(group1) \n",
    "    combined_data = np.concatenate([group1, group2])\n",
    "\n",
    "    count_extreme_values = 0\n",
    "    for i in range(num_samples):\n",
    "        np.random.shuffle(combined_data)      \n",
    "        perm_group1 = combined_data[:len(group1)]\n",
    "        perm_group2 = combined_data[len(group1):]        \n",
    "        perm_diff = np.mean(perm_group2) - np.mean(perm_group1)\n",
    "        if perm_diff >= observed_diff:\n",
    "            count_extreme_values += 1\n",
    "\n",
    "    p_value = count_extreme_values / num_samples    \n",
    "    return p_value\n",
    "\n",
    "\n",
    "p_value = permutation_test(group_a, group_b)\n",
    "print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to use the same dataset to do another A/B testing. We suspect that instructors are the ones who can get more useful information from the search feature, so perhaps non-instructors didn't touch the search feature because it was genuinely not relevant to them.\n",
    "\n",
    "So we decide to repeat the above analysis looking only at instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. If using the same dataset to do this analysis, do you feel like we're p-hacking? If so, what can we do with it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** [Using the same dataset to conduct another analysis based on a smaller subset consisting of instructor samples could be considered as p-hacking, especially if this subgroup analysis wasn't planned before looking at the data. This is because the decision to focus on instructors is influenced by the data itself, rather than a hypothesis set a priori.\n",
    "\n",
    "If must conduct the analysis on the subset, we should decrease the significance levels o account for the increased risk of type I errors. If possible, the best way should be to do the analysis using a new dataset collected from a different time period or a different set of users to see if the effect holds.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Chi-squared Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tens of different hypothesis testing methods. It's impossible to cover all of them in one week. Given that this is an important topic in statistics, I highly recommend using your free time to learn some other popular ones such as <a href=\"https://en.wikipedia.org/wiki/Chi-squared_test\">Chi-squared test</a>, <a href=\"https://en.wikipedia.org/wiki/G-test\">G-test</a>, <a href=\"https://en.wikipedia.org/wiki/Student%27s_t-test\">T-test</a>, and <a href=\"https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\">Mannâ€“Whitney U test</a>.\n",
    "\n",
    "On the searchlog dataset, there are two categorical columns: `is_instructor` and `search_ui`. In Task D, your job is to first learn how a Chi-Squired test works by yourself and then use it to test whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please write code to compute the Chi-squared stat. Note that you are **not** allowed to call an existing function (e.g., stats.chi2, chi2_contingency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Statistic: 0.6731740891275046\n"
     ]
    }
   ],
   "source": [
    "#<-- Write Your Code -->\n",
    "is_instructor = df['is_instructor']\n",
    "search_ui = df['search_ui']\n",
    "\n",
    "# Step 1: Create a contingency table\n",
    "contingency_table = {}\n",
    "for i, ui in enumerate(search_ui):\n",
    "    if is_instructor[i] not in contingency_table:\n",
    "        contingency_table[is_instructor[i]] = {}\n",
    "    if ui not in contingency_table[is_instructor[i]]:\n",
    "        contingency_table[is_instructor[i]][ui] = 1\n",
    "    else:\n",
    "        contingency_table[is_instructor[i]][ui] += 1\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "categories = sorted(set(search_ui))\n",
    "contingency_matrix = np.array([[contingency_table[True].get(category, 0) for category in categories],\n",
    "                               [contingency_table[False].get(category, 0) for category in categories]])\n",
    "\n",
    "# Step 2: Calculate expected frequencies\n",
    "row_totals = contingency_matrix.sum(axis=1)\n",
    "col_totals = contingency_matrix.sum(axis=0)\n",
    "total = contingency_matrix.sum()\n",
    "\n",
    "expected_frequencies = np.outer(row_totals, col_totals) / total\n",
    "\n",
    "# Step 3: Compute the Chi-Squared statistic\n",
    "chi_squared_stat = ((contingency_matrix - expected_frequencies) ** 2 / expected_frequencies).sum()\n",
    "# chi_squared_stat_yates = ((abs(contingency_matrix - expected_frequencies) - 0.5) ** 2 / expected_frequencies).sum()\n",
    "\n",
    "print(f\"Chi-Squared Statistic: {chi_squared_stat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please explain how to use Chi-squared test to determine whether `is_instructor` and `search_ui` are correlated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.** [ Here are the steps to use Chi-squared test:\n",
    "\n",
    "1. Formulate Hypotheses\n",
    "    - Null Hypothesis (H0): There is no association between is_instructor status and the search_ui version. They are independent.\n",
    "\n",
    "    - Alternative Hypothesis (H1): There is an association between is_instructor status and the search_ui version. They are not independent.\n",
    "\n",
    "\n",
    "2. Compute Chi-squared Statistic: As is shown above, calculate the Chi-squared Statistic from Contingency Table\n",
    "\n",
    "3. Determine the P-value: The p-value is the probability of observing a chi-squared statistic at least as extreme as the one calculated, under the null hypothesis. Compare the p-value against a significance level (e.g., 0.05) to decide whether to reject the null hypothesis.\n",
    "\n",
    "4. Make a Decision:\n",
    "    - If the p-value is less than or equal to the significance level, reject the null hypothesis and conclude that there is a statistically significant association between is_instructor and search_ui.\n",
    "\n",
    "    - If the p-value is greater than the significance level,  fail to reject the null hypothesis and conclude that there is not enough evidence to claim an association.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in this notebook, and submit it to the CourSys activity Assignment 9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
